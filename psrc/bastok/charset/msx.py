from    bastok.charset  import *

__all__ = [ 'Charset', 'CHARMAP' ]

####################################################################
#   Characters used for blank glyphs.
#
#   In all standard MSX charsets code 0x00 is a blank glyph, the same as
#   ASCII space, and some charsets have further blank glyphs. To properly
#   round-trip these we must use different Unicode characters for each
#   differently-coded blank.
#
#   The digraphs given below as `dg:XY` are from `RFC 1345`_. The ones
#   given as `sd:XY` are not standard digraphs, but are suggested ones you
#   may add to your editor. In Vim you can press Ctrl-K followed by X and Y
#   to enter a character using a digraph, and you may also define your own
#   digraphs matching `sd:XY` entries. See vim's `:help digraph` for more
#   information on this.
#
#   .. _RFC 1345: https://tools.ietf.org/html/rfc1345

#   Code 0x00. The association should be obvious.
#
C00 = '\u2205'  # âˆ… EMPTY SET (dg:0/)

#   Japanese has a blank instead of the white triangle at 0x7F, but since
#   it does not have a white triangle elsewhere, we use it as the
#   placeholder character here. This might, however, be confusing; if it
#   proves to be so we should probably change it to `â ¿` BRAILE PATTERN
#   DOTS-123456 (see below for more on this).
#
C7F = '\u25B3'  # â–³ WHITE UP-POINTING TRIANGLE (dg:uT)

#   We use BRAILLE PATTERN DOTS-nnn for other blank glyphs because these
#   are very obviously not from any standard MSX or Japanese character set
#   and are often part of standard modern character sets.
#
C90 = '\u280F'  # â  DOTS-1234 (sd:b4)
CA0 = '\u2817'  # â — DOTS-1235 (sd:b5)
CFE = '\u2827'  # â § DOTS-1236 (sd:b6)

####################################################################
#   ASCII characters
#
#   These are common to all MSX charsets. These codes include neither
#   control chars $00-$1F nor $7F (ASCII DEL), which is a glyph code that
#   varies amongst the MSX character sets.

C_ASCII = tuple([ (c, chr(c)) for c in range(0x20,0x7F) ])

assert len(C_ASCII) == 0x5F, hex(len(C_ASCII))

####################################################################
#   International charset
#
#   Some of this is the same as code page 437, the original IBM PC
#   character set. When in doubt, the character from that has been used.
#
#   0x10 and 0x1F are vertical+horizontal box drawing characters similar to
#   0x15 `â”¼`, except that they do not extend all the way to the edge of the
#   horizontal resp. vertical edges of the character cell. Unicode box
#   drawing has no equivalants to these, and I doubt that the legacy
#   charset versions are widely available in any commmon fonts, so here we
#   use a couple of obviously different Unicode characters to help avoid
#   confusion. If you do have fonts with these legacy characters, you can
#   redefine these with a custom character mapping.
#
VH_shortH = '\u256A'    # â•ª BOX DRAWINGS VERTICAL SINGLE AND HORIZONTAL DOUBLE
VH_shortV = '\u256B'    # â•« BOX DRAWINGS VERTICAL DOUBLE AND HORIZONTAL SINGLE

LO_int = ''.join([C00,
        'â˜ºâ˜»â™¡â™¢â™£â™ â€¢â—˜â—‹â—™â™‚â™€â™ªâ™«â˜¼',
        VH_shortH, 'â”´â”¬â”¤â”œâ”¼â”‚â”€â”Œâ”â””â”˜â•³â•±â•²', VH_shortV,
        ])

#   There's not complete agreement on what all the Code Page 437 characters
#   are; see the notes at https://en.wikipedia.org/wiki/Code_page_437 .
HI_int = ''.join([
        'Ã‡Ã¼Ã©Ã¢Ã¤Ã Ã¥Ã§ÃªÃ«Ã¨Ã¯Ã®Ã¬Ã„Ã…',     # 8x row from CP 437
        'Ã‰Ã¦Ã†Ã´Ã¶Ã²Ã»Ã¹Ã¿Ã–ÃœÂ¢Â£Â¥â‚§Æ’',     # 9x row from CP 437
        'Ã¡Ã­Ã³ÃºÃ±Ã‘ÂªÂºÂ¿âŒÂ¬Â½Â¼Â¡Â«Â»',     # Ax row from CP 437
        'ÃƒÃ£Ä¨Ä©Ã•ÃµÅ¨Å©Ä²Ä³Â¾âˆ½â—‡â€°Â¶Â§',     # Bx XXX incomplete
        'â–‚â–šâ–†ğŸ®‚â–¬ğŸ®…â–â–â–ŠğŸ®‡ğŸ®ŠğŸ®™ğŸ®˜ğŸ­­ğŸ­¯ğŸ­¬',     # Cx from Wikipedia "MSX Character Set"
        'ğŸ­®ğŸ®šğŸ®›â–˜â–—â–â––ğŸ®–Î”â€¡Ï‰â–ˆâ–„â–Œâ–â–€',     # Dx from Wikipedia "MSX Character Set"
        'Î±ÃŸÎ“Ï€Î£ÏƒÂµÏ„Î¦Î˜Î©Î´âˆÏ†âˆˆâˆ©',     # Ex row from CP 437, possibly excepting 0xEE
        'â‰¡Â±â‰¥â‰¤âŒ âŒ¡Ã·â‰ˆÂ°âˆ™Â·âˆšâ¿Â²â– â–’',     # Fx row from CP 437, mostly
        ])

assert len(LO_int) == 0x20, hex(len(LO_int))
assert len(HI_int) == 0x80, hex(len(HI_int))

C_INT = tuple(zip(range(0x00, 0x20), LO_int)) \
     + C_ASCII + ((0x7F,C7F),) \
     + tuple(zip(range(0x80, 0x100), HI_int)) \
     + ()

####################################################################
#   Japanese charset

LO_ja = ''.join([C00,
        'æœˆç«æ°´æœ¨é‡‘åœŸæ—¥å¹´å††æ™‚åˆ†ç§’ç™¾åƒä¸‡',
        'Ï€â”´â”¬â”¤â”œâ”¼â”‚â”€â”Œâ”â””â”˜â•³å¤§ä¸­å°',
        ])
HI_ja = ''.join([
        'â™ â™¡â™£â™¢â—‹â—ã‚’ããƒã…ã‡ã‰ã‚ƒã‚…ã‚‡ã£',
        C90, 'ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ã',
        CA0, 'ã€‚ã€Œã€ã€ãƒ»ãƒ²ã‚¡ã‚£ã‚¥ã‚§ã‚©ãƒ£ãƒ¥ãƒ§ãƒƒ',
        'ãƒ¼ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½',
        'ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒ',
        'ãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ¯ãƒ³ã‚›ã‚œ',
        'ãŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾',
        'ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚“', CFE, 'â–ˆ',
        ])

assert len(LO_ja) == 0x20, hex(len(LO_ja))
assert len(HI_ja) == 0x80, hex(len(HI_ja))

C_JA = tuple(zip(range(0x00, 0x20), LO_ja)) \
     + chrsub(C_ASCII, (0x5C, 'Â¥')) + ((0x7F,C7F),) \
     + tuple(zip(range(0x80, 0x100), HI_ja)) \
     + ()

####################################################################
#   Dictionary of all standard charset/Unicode mappings

CHARMAP = {
    'int':  Charset('International (North America/Europe)', C_INT),
    'ja':   Charset('Japanese (MSX2)', C_JA),
    'ja1':  Unimplemented('ja1', 'Japanese (MSX1, different hiragana)'),
    'ar':   Unimplemented('ar', 'Arabic'),
    'pt':   Unimplemented('pt', 'Portuguese (Brazil)'),
    'BR':   Unimplemented('BR', "alias for 'pt'"),
    'ru':   Unimplemented('ru', 'Russian'),
}
